{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-nomic\n",
      "  Obtaining dependency information for langchain-nomic from https://files.pythonhosted.org/packages/77/3a/f87f416dd1778e5ae62929b9627697b19b3d33e48b674cac51e5c9f3cb90/langchain_nomic-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading langchain_nomic-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-nomic) (0.1.52)\n",
      "Collecting nomic<4.0.0,>=3.0.29 (from langchain-nomic)\n",
      "  Downloading nomic-3.0.29.tar.gz (44 kB)\n",
      "     ---------------------------------------- 0.0/44.2 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/44.2 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 20.5/44.2 kB 162.5 kB/s eta 0:00:01\n",
      "     -------------------------- ----------- 30.7/44.2 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 44.2/44.2 kB 240.8 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (0.1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (2.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3,>=0.1.46->langchain-nomic) (8.2.3)\n",
      "Requirement already satisfied: click in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (8.1.7)\n",
      "Collecting jsonlines (from nomic<4.0.0,>=3.0.29->langchain-nomic)\n",
      "  Obtaining dependency information for jsonlines from https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl.metadata\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting loguru (from nomic<4.0.0,>=3.0.29->langchain-nomic)\n",
      "  Obtaining dependency information for loguru from https://files.pythonhosted.org/packages/03/0a/4f6fed21aa246c6b49b561ca55facacc2a44b87d65b8b92362a8e99ba202/loguru-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (13.7.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (2.31.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (1.24.3)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (2.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (4.66.2)\n",
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (11.0.0)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (9.4.0)\n",
      "Requirement already satisfied: pyjwt in c:\\programdata\\anaconda3\\lib\\site-packages (from nomic<4.0.0,>=3.0.29->langchain-nomic) (2.4.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain-nomic) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain-nomic) (3.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-nomic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-nomic) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain-nomic) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nomic<4.0.0,>=3.0.29->langchain-nomic) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nomic<4.0.0,>=3.0.29->langchain-nomic) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from requests->nomic<4.0.0,>=3.0.29->langchain-nomic) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->nomic<4.0.0,>=3.0.29->langchain-nomic) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nomic<4.0.0,>=3.0.29->langchain-nomic) (0.4.6)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonlines->nomic<4.0.0,>=3.0.29->langchain-nomic) (22.1.0)\n",
      "Collecting win32-setctime>=1.0.0 (from loguru->nomic<4.0.0,>=3.0.29->langchain-nomic)\n",
      "  Obtaining dependency information for win32-setctime>=1.0.0 from https://files.pythonhosted.org/packages/0a/e6/a7d828fef907843b2a5773ebff47fb79ac0c1c88d60c0ca9530ee941e248/win32_setctime-1.1.0-py3-none-any.whl.metadata\n",
      "  Downloading win32_setctime-1.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain-nomic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain-nomic) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain-nomic) (2023.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->nomic<4.0.0,>=3.0.29->langchain-nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->nomic<4.0.0,>=3.0.29->langchain-nomic) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.29->langchain-nomic) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.0.29->langchain-nomic) (1.16.0)\n",
      "Downloading langchain_nomic-0.1.1-py3-none-any.whl (3.8 kB)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.5 kB ? eta -:--:--\n",
      "   ---------------------------------------  61.4/62.5 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 62.5/62.5 kB 843.7 kB/s eta 0:00:00\n",
      "Downloading win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
      "Building wheels for collected packages: nomic\n",
      "  Building wheel for nomic (pyproject.toml): started\n",
      "  Building wheel for nomic (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for nomic: filename=nomic-3.0.29-py3-none-any.whl size=44800 sha256=089de288fde42757ec0d79e725f43ce5c38d44867ea834a93c11ab7d1e7a71cf\n",
      "  Stored in directory: c:\\users\\anoop maurya\\appdata\\local\\pip\\cache\\wheels\\f8\\e7\\ac\\53f4833a5cc144a45086515cf2052232f116e0fc9103ff2be1\n",
      "Successfully built nomic\n",
      "Installing collected packages: win32-setctime, jsonlines, loguru, nomic, langchain-nomic\n",
      "Successfully installed jsonlines-4.0.0 langchain-nomic-0.1.1 loguru-0.7.2 nomic-3.0.29 win32-setctime-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nomic.exe is installed in 'C:\\Users\\Anoop Maurya\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-nomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script langchain-server.exe is installed in 'C:\\Users\\Anoop Maurya\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script chroma.exe is installed in 'C:\\Users\\Anoop Maurya\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "crewai 0.28.2 requires langchain<0.2.0,>=0.1.10, but you have langchain 0.2.1 which is incompatible.\n",
      "embedchain 0.1.99 requires chromadb<0.5.0,>=0.4.17, but you have chromadb 0.5.0 which is incompatible.\n",
      "embedchain 0.1.99 requires langchain<0.2.0,>=0.1.4, but you have langchain 0.2.1 which is incompatible.\n",
      "embedchain 0.1.99 requires tiktoken<0.6.0,>=0.5.2, but you have tiktoken 0.7.0 which is incompatible.\n",
      "langchain-anthropic 0.1.4 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.2.1 which is incompatible.\n",
      "langchain-experimental 0.0.58 requires langchain<0.2.0,>=0.1.17, but you have langchain 0.2.1 which is incompatible.\n",
      "langchain-experimental 0.0.58 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.1 which is incompatible.\n",
      "langchain-google-genai 0.0.5 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.2.1 which is incompatible.\n",
      "langchain-groq 0.0.1 requires langchain-core<0.2,>=0.1, but you have langchain-core 0.2.1 which is incompatible.\n",
      "langchain-openai 0.0.5 requires langchain-core<0.2,>=0.1.16, but you have langchain-core 0.2.1 which is incompatible.\n",
      "langchain-openai 0.0.5 requires tiktoken<0.6.0,>=0.5.2, but you have tiktoken 0.7.0 which is incompatible.\n",
      "llama-index-readers-file 0.1.13 requires pypdf<5.0.0,>=4.0.1, but you have pypdf 3.17.4 which is incompatible.\n",
      "llama-index-vector-stores-chroma 0.1.6 requires chromadb<0.5.0,>=0.4.22, but you have chromadb 0.5.0 which is incompatible.\n",
      "llmx 0.0.18a0 requires openai==0.28.1, but you have openai 1.14.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain-nomic langchain_community tiktoken langchainhub chromadb langchain langgraph tavily-python gpt4all langchain-text-splitters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gpt4all in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from gpt4all) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from gpt4all) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->gpt4all) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anoop maurya\\appdata\\roaming\\python\\python311\\site-packages (from requests->gpt4all) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->gpt4all) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->gpt4all) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gpt4all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__c8997e1750af4e6b80a73679c44fedf6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"phi3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     20\u001b[0m doc_splits \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs_list)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Add to vectorDB\u001b[39;00m\n\u001b[0;32m     23\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m Chroma\u001b[38;5;241m.\u001b[39mfrom_documents(\n\u001b[0;32m     24\u001b[0m     documents\u001b[38;5;241m=\u001b[39mdoc_splits,\n\u001b[0;32m     25\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag-chroma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 26\u001b[0m     embedding\u001b[38;5;241m=\u001b[39mGPT4AllEmbeddings(),\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m validator(cls_, values)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_community\\embeddings\\gpt4all.py:39\u001b[0m, in \u001b[0;36mGPT4AllEmbeddings.validate_environment\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt4all\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embed4All\n\u001b[0;32m     38\u001b[0m     values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Embed4All(\n\u001b[1;32m---> 39\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m         n_threads\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_threads\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     41\u001b[0m         device\u001b[38;5;241m=\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalues\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt4all_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     43\u001b[0m     )\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import gpt4all library. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install the gpt4all library to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse this embedding model: pip install gpt4all\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     49\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'model_name'"
     ]
    }
   ],
   "source": [
    "### Index\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=GPT4AllEmbeddings(),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
